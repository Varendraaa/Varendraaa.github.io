[{"content":"","date":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories"},{"content":"","date":null,"permalink":"/tags/chromadb/","section":"Tags","summary":"","title":"Chromadb"},{"content":"","date":null,"permalink":"/tags/chunkig/","section":"Tags","summary":"","title":"Chunkig"},{"content":"This is a very summarised overview of my MSc Thesis Project, done at the University of Dundee. It focuses on the creation and development of a Doom-like 3D FPS game, and its underlying engine, completely from first principles. It utilises simple, open-source C++ libraries to support some features, but every other aspect was done manually by the game code.\nSince the thesis itself was over 18000 words, I\u0026rsquo;ll not be going into a similar level of detail here. I\u0026rsquo;ll highlight some of the ways I solved certain complex problems in development. If you\u0026rsquo;re interested in reading it, please do send me a message.\nBackground #For my thesis, there were a couple projects I was interested in. I ultimately decided to go with the game engine development for the following reasons:\nIt was something I\u0026rsquo;d be motivated to develop, and therefore avoid falling into the trap that is lack of motivation. It offered me the opportunity to learn about graphics programming, specifically about OpenGL. It was a really cool idea. I mean, I\u0026rsquo;m making a game that people could later play, and enjoy. EXTREMELY DOPE. However, I severely underestimated the sheer amount of work required to get a good game going. I had a development window of around 8 weeks max, and I ended up working maybe 12-15 hours a day, learning as I went along.\nDevelopment #Initial Setup #My project ran over a 12 week timeline, from May 23rd 2024 to August 22 2024, but that also included the thesis write-up, poster creation and presentation preparation. My supervisor, Dr. Iain Martin, and I set out a goal of getting the core game done within 8-9 weeks, to allow enough time for revision, modification and other improvements.\nThe first couple weeks was spent getting up to speed with understanding OpenGL and the graphics pipeline. This was paramount since I\u0026rsquo;d need to learn how to manipulate objects throughout the pipeline if I ever wanted to even display a single pixel on the screen. Some fantastic resources I used were:\nLearnOpenGL OpenGL-tutorial FreeCodeCamp\u0026rsquo;s OpenGL Tutorials by Victor Gordon By the end of week 3, I had my first window displayed, my \u0026ldquo;Hello World\u0026rdquo; OpenGL triangle rendered, and a basic framework set up to let me start crafting my game.\nPicking a Game Concept #Early on, I created two gaming concepts that I\u0026rsquo;d be interested in making, each with their pros and cons:\nA racing game not dissimilar to MarioKart or F-Zero, where players could race each other or AI opponents around a track. Pros: Cons: A Dungeon Crawler FPS inspired by classics such as Wolfenstein and Doom, where a player character explores a dark dungeon while fighting off enemies. Pros: Cons: Eventually, I settled on the Doom-like FPS game, and set about making the game work.\nFiguring out FPS Games #Let me be the first to say, your first game will probably be one of the most fun, yet challenging things you work on. FPS games are among the most complex type of games to create, especially without the use of an engine. They need many complex systems to all work in tandem, and the best way to structure this is to look at Design Patterns.\n","date":"21 August 2024","permalink":"/projects/game-engine/","section":"Projects","summary":"'","title":"Doom-like Game Engine Development"},{"content":"","date":null,"permalink":"/tags/gabriel-garcia-marquez/","section":"Tags","summary":"","title":"Gabriel-Garcia-Marquez"},{"content":"","date":null,"permalink":"/tags/langchain/","section":"Tags","summary":"","title":"Langchain"},{"content":"","date":null,"permalink":"/tags/llama3-1/","section":"Tags","summary":"","title":"Llama3-1"},{"content":"","date":null,"permalink":"/tags/llama3-2/","section":"Tags","summary":"","title":"Llama3-2"},{"content":"","date":null,"permalink":"/tags/llm/","section":"Tags","summary":"","title":"Llm"},{"content":"","date":null,"permalink":"/tags/nomic/","section":"Tags","summary":"","title":"Nomic"},{"content":"","date":null,"permalink":"/tags/ollama/","section":"Tags","summary":"","title":"Ollama"},{"content":"","date":null,"permalink":"/projects/","section":"Projects","summary":"","title":"Projects"},{"content":"","date":null,"permalink":"/tags/rag/","section":"Tags","summary":"","title":"Rag"},{"content":"","date":null,"permalink":"/tags/retrieval-augmented-generation/","section":"Tags","summary":"","title":"Retrieval-Augmented-Generation"},{"content":"","date":null,"permalink":"/tags/retriever/","section":"Tags","summary":"","title":"Retriever"},{"content":"","date":null,"permalink":"/categories/software/","section":"Categories","summary":"","title":"Software"},{"content":"","date":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags"},{"content":"","date":null,"permalink":"/tags/web-scraping/","section":"Tags","summary":"","title":"Web-Scraping"},{"content":"\rWelcome to my hub for my projects and musings. I\u0026rsquo;m currently focusing on Machine Learning, Graphics Programming, Game Engine Development and UI/UX.\rHere, you\u0026rsquo;ll find:\nProject Breakdowns: A closer look at my work and current projects. Blog Posts: Short articles on matters that I find interesting. ","date":null,"permalink":"/","section":"","summary":"","title":""},{"content":"About Me #I\u0026rsquo;m a newly minted software developer that loves to blend his creative and technical sides into creating fun products that users enjoy. In my spare time, I\u0026rsquo;m just a chill guy that enjoys weightlifting, photography and cooking.\nHow I Got Here #I originally obtained my Bachelor\u0026rsquo;s in Petroleum Geoscience from the University of the West Indies, and spent the next 5+ years as a Geophysicist within the local Oil and Gas Industry, focusing on seismic data analysis and interpretation, data management and policy development. I was able to work on some amazing projects, such as hydrocarbon resource analysis of offshore deepwater environments, and development of a policy framework to guide licensing round evaluations.\nadd image here\nAlthough I enjoyed what I was doing, I began suffering from burnout and overwork, likely a leftover effect from the Covid-19 pandemic times. Since I was always interested in software development, and had already begun automating my day to day analytical workflows using Python, I decided to take a risk to pivot away and pursue my Masters in Computer Science at the University of Dundee.\nadd image here\nMoving to a completely new country to study in a bid to take my career in a new direction was a surreal experience. I\u0026rsquo;m truly grateful that I was able to make that choice for myself, as I met some amazing people and got to learn so many things. I graduated as the Best Overall Student in my MSc cohort, and I\u0026rsquo;m looking forward to things ahead.\nExperience #Education # MSc. Computer Science (Distinction)\nUniversity of Dundee 2023 - 2024 Bsc. Petroleum Geoscience(Honours)\nUniversity of the West Indies 2015 - 2018 ","date":null,"permalink":"/about/","section":"","summary":"","title":"Hi there, Iâ€™m Varendra!"},{"content":"\rI\u0026rsquo;m currently redoing this project, based on some improvements shown to me by my classmate, Hannah Gordon. I\u0026rsquo;m also planning to separate the binary classification and multi-class classification into seperate posts for brevity\u0026rsquo;s sake.\rThis project, undertaken as part of Machine Learning Module at the University of Dundee, focuses on using deep learning to classify medical images. It evaluates the performance of the neural network architectures across binary and multi-class classification tasks, showcasing the potential of machine learning in healthcare applications.\nBackground #MedMNIST is a collection of 10 datasets of 28x28 pixel medical images. For this project, two different datasets were chosen, one for binary classification and one for multi-class classification. Each dataset was evaluated using three different networks:\nSample ConvNet : A baseline convolutional neural network provided as part of the coursework. Dense-Only Network : A fully connected network without convolutional layers but with comparable total parameters to the baseline ConvNet. Custom ConvNet : A self-designed deep neural network incorporating advanced design principles, regularization methods, and data augmentation to optimize performance. The networks were built using Google Colab for a couple reasons:\nThe cloud platform meant that there were no incompatibilities between different framework versions. Testing and adjusting network models in the cloud was far easier and didn\u0026rsquo;t require dedicated GPUs. The two chosen datasets were:\nPneumoniaMNIST for binary classification (presence or absence of pneumonia). OrganCMNIST for multi-class classification (predicting organ types). Part 1: Binary Classification of Pneumonia Images #Baseline Convnet #First, I looked at the sample covnet provided by the University, which consisted of the following architecture:\nTwo convolutional layers with ReLU activation and max pooling. A dense output layer with a softmax activation function. Total params: 18379 Trainable params: 18379 from keras import layers from keras import models model_1 = models.Sequential() model_1.add(keras.layers.Conv2D(32, (3, 3), activation=\u0026#39;relu\u0026#39;, input_shape=(28, 28, 1))) model_1.add(keras.layers.MaxPooling2D((2, 2))) model_1.add(keras.layers.Conv2D(32, (3, 3), activation=\u0026#39;relu\u0026#39;)) model_1.add(keras.layers.MaxPooling2D((2, 2))) model_1.add(layers.Flatten()) model_1.add(layers.Dense(11, activation=\u0026#39;softmax\u0026#39;)) model_1.summary() The model was compiled using stochastic gradient descent (SGD) with a learning rate of 0.001 and evaluated using binary cross-entropy loss.\nmodel_1.compile(optimizer=keras.optimizers.SGD(learning_rate=0.001), loss=\u0026#39;binary_crossentropy\u0026#39;, metrics=[\u0026#39;accuracy\u0026#39;]) // Add Results here Binary Base Model Accuracy Plot\rBinary Base Model Loss Plot\rDense Network (Without Convolutions) #To look at the importance of spatial feature extraction, a dense-only network was also tested. This network replaced convolutional layers with fully connected layers, while keeping the total parameter count similar to the ConvNet.\nArchitecture Details:\nInput images were flattened into 1D arrays. Three fully connected layers with 128, 64, and 32 neurons, respectively. Dropout layers were added to prevent overfitting. from keras import layers, models model_dense = models.Sequential() model_dense.add(layers.Flatten(input_shape=(28, 28, 1))) # Flattening the image model_dense.add(layers.Dense(128, activation=\u0026#39;relu\u0026#39;)) model_dense.add(layers.Dropout(0.3)) # Regularization model_dense.add(layers.Dense(64, activation=\u0026#39;relu\u0026#39;)) model_dense.add(layers.Dropout(0.3)) model_dense.add(layers.Dense(1, activation=\u0026#39;sigmoid\u0026#39;)) # Sigmoid activation model_dense.compile(optimizer=\u0026#39;adam\u0026#39;, loss=\u0026#39;binary_crossentropy\u0026#39;, metrics=[\u0026#39;accuracy\u0026#39;]) // Add results here Binary Dense Model Accuracy Plot\rBinary Dense Model Loss Plot\rChallenges Observed:\nDense networks struggled to capture spatial patterns in the images, resulting in lower performance compared to ConvNets. Dropout regularization improved generalization but did not fully bridge the performance gap. Key Insights:\nDense layers alone lack the ability to identify localized features, highlighting the importance of convolutions for tasks involving image data. Custom Convnet #The custom ConvNet incorporated the following enhancements:\nDepth and Complexity: Increased convolutional layers to capture more detailed features. Regularization: Added dropout layers after each dense layer to prevent overfitting. Batch Normalization: Improved training stability. Data Augmentation: Improved dataset diversity with transformations like rotation, flipping, and zoom. from keras.preprocessing.image import ImageDataGenerator # Data augmentation datagen = ImageDataGenerator(rotation_range=20, width_shift_range=0.2, height_shift_range=0.2, horizontal_flip=True) # Custom ConvNet model_custom = models.Sequential() model_custom.add(layers.Conv2D(32, (3, 3), activation=\u0026#39;relu\u0026#39;, input_shape=(28, 28, 1))) model_custom.add(layers.BatchNormalization()) model_custom.add(layers.MaxPooling2D((2, 2))) model_custom.add(layers.Dropout(0.3)) # Regularization model_custom.add(layers.Conv2D(64, (3, 3), activation=\u0026#39;relu\u0026#39;)) model_custom.add(layers.BatchNormalization()) model_custom.add(layers.MaxPooling2D((2, 2))) model_custom.add(layers.Dropout(0.4)) model_custom.add(layers.Flatten()) model_custom.add(layers.Dense(128, activation=\u0026#39;relu\u0026#39;)) model_custom.add(layers.Dropout(0.5)) model_custom.add(layers.Dense(1, activation=\u0026#39;sigmoid\u0026#39;)) # Sigmoid activation model_custom.compile(optimizer=\u0026#39;adam\u0026#39;, loss=\u0026#39;binary_crossentropy\u0026#39;, metrics=[\u0026#39;accuracy\u0026#39;]) Binary Custom Model Accuracy Plot\rBinary Custom Model Loss Plot\rResults: The custom ConvNet achieved the best performance among the three models, with significantly improved accuracy and generalization.\nKey Design Takeaways:\nBatch normalization and dropout worked synergistically to stabilize training and reduce overfitting. Data augmentation allowed the model to learn more robust representations. Part 2: Multi-Class classification of Organ Images #Baseline ConvNet #The baseline ConvNet, adapted for multi-class classification, consisted of two convolutional layers followed by a softmax-activated dense output layer for probability distributions.\nTwo convolutional layers with ReLU activation and max-pooling. A dense output layer with softmax activation for multi-class probability distributions. Total parameters: 18,379 model_1 = models.Sequential() model_1.add(layers.Conv2D(32, (3, 3), activation=\u0026#39;relu\u0026#39;, input_shape=(28, 28, 1))) model_1.add(layers.MaxPooling2D((2, 2))) model_1.add(layers.Conv2D(32, (3, 3), activation=\u0026#39;relu\u0026#39;)) model_1.add(layers.MaxPooling2D((2, 2))) model_1.add(layers.Flatten()) model_1.add(layers.Dense(11, activation=\u0026#39;softmax\u0026#39;)) # Softmax for multi-class model_1.compile(optimizer=\u0026#39;adam\u0026#39;, loss=\u0026#39;categorical_crossentropy\u0026#39;, metrics=[\u0026#39;accuracy\u0026#39;]) // Add results here\nDense Network (Without Convolutions) #For multi-class classification, the dense network used three fully connected layers with dropout for regularization.\nThree fully connected layers with 128, 64, and 32 neurons, respectively. Dropout layers for regularization. Softmax activation in the output layer to produce class probabilities. model_dense = models.Sequential() model_dense.add(layers.Flatten(input_shape=(28, 28, 1))) model_dense.add(layers.Dense(128, activation=\u0026#39;relu\u0026#39;)) model_dense.add(layers.Dropout(0.3)) model_dense.add(layers.Dense(64, activation=\u0026#39;relu\u0026#39;)) model_dense.add(layers.Dropout(0.3)) model_dense.add(layers.Dense(11, activation=\u0026#39;softmax\u0026#39;)) # 11 classes model_dense.compile(optimizer=\u0026#39;adam\u0026#39;, loss=\u0026#39;categorical_crossentropy\u0026#39;, metrics=[\u0026#39;accuracy\u0026#39;]) // Add results here\nCustom ConvNet #The custom ConvNet was enhanced for multi-class classification by:\nIncreased Depth: Added a third convolutional layer for deeper feature extraction. Regularization: Introduced higher dropout rates and learning rate scheduling model_custom = models.Sequential() model_custom.add(layers.Conv2D(32, (3, 3), activation=\u0026#39;relu\u0026#39;, input_shape=(28, 28, 1))) model_custom.add(layers.BatchNormalization()) model_custom.add(layers.MaxPooling2D((2, 2))) model_custom.add(layers.Dropout(0.3)) model_custom.add(layers.Conv2D(64, (3, 3), activation=\u0026#39;relu\u0026#39;)) model_custom.add(layers.BatchNormalization()) model_custom.add(layers.MaxPooling2D((2, 2))) model_custom.add(layers.Dropout(0.4)) model_custom.add(layers.Conv2D(128, (3, 3), activation=\u0026#39;relu\u0026#39;)) model_custom.add(layers.BatchNormalization()) model_custom.add(layers.MaxPooling2D((2, 2))) model_custom.add(layers.Dropout(0.5)) model_custom.add(layers.Flatten()) model_custom.add(layers.Dense(256, activation=\u0026#39;relu\u0026#39;)) model_custom.add(layers.Dropout(0.5)) model_custom.add(layers.Dense(11, activation=\u0026#39;softmax\u0026#39;)) model_custom.compile(optimizer=\u0026#39;adam\u0026#39;, loss=\u0026#39;categorical_crossentropy\u0026#39;, metrics=[\u0026#39;accuracy\u0026#39;]) // Add results here\nKey Insights\nConvNets Perform Better: Convolutional layers consistently outperformed dense-only networks in image-based tasks. Regularization Works: Dropout, batch normalization, and data augmentation reduced overfitting. Custom Architectures Excel: Tailored designs provided the best performance across both tasks. ","date":"16 March 2024","permalink":"/projects/computer-vision-binary/","section":"Projects","summary":"This project evaluates the performance of neural networks in medical image analysis for disease detection.","title":"Computer Vision using Deep Learning - Binary Classification"},{"content":"A web app that combines two APIs to make a useful application\nSee the app here #About #This was my second assignment for my Web Development Module at the University of Dundee. It\u0026rsquo;s written using HTML, CSS and Javascript, with support from JQuery and Material Design Bootstrap. It was my first time working with Javascript and the JSON notation, and was developed over a period of 4 weeks.\nIt uses two API\u0026rsquo;s for its functionality:\nWeather API Ticketmaster API Initially, I looked at all freely available API\u0026rsquo;s from this convenient repository and tried to figure out two things:\nWhat app would I actually be interested in making? What two API\u0026rsquo;s would function well together to make a useful application? I decided on putting together the two aforementioned API\u0026rsquo;s to create an application that allows a user to check both the weather forecast and upcoming events in the area, simply by inputing a designated location. I was also inspired by the Windows 11 Weather app.\nDesign #The initial layout was built based on a basic wireframe design of my concept in Mockflow (Figma was not something I was familiar with, nor had time to get familiar with).\nI initially planned to integrate a geocoding API such as Mapbox API to generate a real-time weather map, but WeatherAPI did not support map tiling so I could not.\nDevelopment #After the initial design was mocked up, I started on developing a base boilerplate website utilising the Material Design Bootstrap (MDB) framework as well as it offered a simple to use, responsive, mobile-first building toolkit. It alos allows every element to scale well across different platforms.\nThe JQuery API was also used to facilitate easy Document Object Model (DOM) traversal.\nI then iterated between using Javascript to fetch API information to create objects that would be inserted into the various sections and then adjusting the HTML and CSS to ensure that the overall framing of the website would stay the same. As mentioned before, the interactive weather map implementation was not feasible due to the Weather API limitations, so the design was subsequently adjusted.\nSince this was my first time working with API data calls and the JSON format, I spent some time getting used to the particular data structures for the different platforms.\nI ran into an issue where the API data for the Weather API was very inconsistent in the dimensions for the icon images for different weather conditions. It essentially contained multiple images of differing sizes, aspect ratio and resolutions. This meant that sometimes they would render incorrectly or be incredibly pixelated. I resolved this by ensuring that all images present in the API were rendered to a set 16:9 ratio.\nI also opted for a very basic colour scheme that had good contrast, which was checked using the colour contrast checker from Coolors.co. Some improvements could be made but, being colourblind myself (deuteranopia), I chose safe colours that I could see well.\n","date":"21 October 2023","permalink":"/projects/api-mashup/","section":"Projects","summary":"'","title":"Weather Event App - API Mashup"}]